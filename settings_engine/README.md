## Массовая загрузка csv файлов в базу данных
### Установка
1. Склонировать репозиторий
2. Создать файл  **.env**
3. Скопривать файл **env_example** в  **.env**
```
cp env_example .env
```
4. Установить необходимые контактные данные базы в файле **.env**
5. Создать виртуальное окружение при первом запуске
```
python3.9 -m venv env
```
6. Запустить виртуальное окружение
```
source env/bin/activate
```
7. Установить зависимости
```
pip install -r requirements.txt
```

### Использование
1. Поместите **csv** файлы для закачки в папку **for_loading**
2. Файлы не должны быть заархивированы
3. Запустите код на исполнение
```
python3.9 loader_history_sql.py
```
4. Об успехах загрузки информация будет выходить в консоль
5. Успешно сохраненные в базу файлы перемещаются в папку **archive**

### Возможные проблемы
1. Файлы с которыми возникли проблемы выведут причину ошибки в консоль, и они остануться в папке **for_loading**
2. Если после запуска *loader_history_sql.py* остались проблемные файлы - запустите loader_history_alc.py
```
python3.9 loader_history_alc.py
```
3. Если пункт выше не помог - надо корректировать **csv** файлы, чтобы у базы данных не было к ним претензий

### Особенности
1. Отличие **..._alc.py** и **..._sql.py** заключается в разных способах загрузки данных.\
**_sql.py** - используются механимы подключения *psycopg2* и запись через *cursor.execute(SQL)*\
**_alc.py** - используется коннектор предоставленный *sqlalchemy* и запись через *pandas df.to_sql*
2. При записи в базу через *pandas df.to_sql* не создается id, а также могут проигнорироваться некоторые ошибки возникающие при использовании *cursor.execute(SQL)*
3. Список таблиц создаваемых и записываемых в базу указан в коде. 
```
table_list = ['rs24', 'lerua', 'maxipro', 'petrovich', 'elcom']
```
4. Какой файл в какую таблицу должен быть записан определяеся через первые 2 буквы названия таблицы.\
То есть когда дойдет очередь до таблицы lerua, программа соберет все файлы в папке начинающиеся на **le** и заканчивающиеся на **.csv** 
